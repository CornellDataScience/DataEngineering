{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .master(\"yarn\") \\\n",
    "        .appName(\"testing\") \\\n",
    "        .config(\"spark.executor.instances\", \"2\") \\\n",
    "        .config(\"spark.executor.memory\",\"1g\") \\\n",
    "        .config(\"spark.driver.memory\",\"2g\") \\\n",
    "        .config(\"spark.executor.cores\",'1') \\\n",
    "        .config(\"spark.scheduler.mode\",\"FIFO\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.tuning import *\n",
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat = spark.read.csv(\"/del2/Reviews.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat = dat.repartition(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- ProductId: string (nullable = true)\n",
      " |-- UserId: string (nullable = true)\n",
      " |-- ProfileName: string (nullable = true)\n",
      " |-- HelpfulnessNumerator: string (nullable = true)\n",
      " |-- HelpfulnessDenominator: string (nullable = true)\n",
      " |-- Score: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Summary: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dat.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id=250076, ProductId='B0029NII3C', UserId='ASALATXVOO93K', ProfileName='\"OC Mom \"\"OC Mom\"\"\"', HelpfulnessNumerator='0', HelpfulnessDenominator='0', Score='3', Time='1337040000', Summary='My cats love this smelly fish', Text=\"My 2 cats are picky tuna lovers and this was all that was available at the time. They still love this, but the smelly fish scent is very strong and the kitchen smells for a bit after they eat it. They still love it. But I don't like the smell. I'd buy it again if there was no other choice. But if there is tuna, I'd go for that instead.\")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the details of the data and dropping irrelevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Id: int, HelpfulnessNumerator: string, HelpfulnessDenominator: string, Score: string, Summary: string, Text: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.drop(\"ProductId\", \"UserId\", \"ProfileName\", \"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- ProductId: string (nullable = true)\n",
      " |-- UserId: string (nullable = true)\n",
      " |-- ProfileName: string (nullable = true)\n",
      " |-- HelpfulnessNumerator: string (nullable = true)\n",
      " |-- HelpfulnessDenominator: string (nullable = true)\n",
      " |-- Score: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Summary: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dat.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score=dat[\"Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
      "|    Id| ProductId|        UserId|         ProfileName|HelpfulnessNumerator|HelpfulnessDenominator|Score|      Time|             Summary|                Text|\n",
      "+------+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
      "|250076|B0029NII3C| ASALATXVOO93K| \"OC Mom \"\"OC Mom\"\"\"|                   0|                     0|    3|1337040000|My cats love this...|My 2 cats are pic...|\n",
      "|250084|B0029NII3C| AYAH5HYV62EXV|    Connie S. Miller|                   0|                     0|    5|1327622400|\"Just what \"\"The ...|\"\"\"The Cat\"\" will...|\n",
      "|250092|B0029NII3C| A1RET8URKV6NV|              Melvin|                   0|                     0|    5|1318896000|My Cat Loves Whis...|\"Cats can be very...|\n",
      "|250100|B0029NII3C|A2FBIW0WJU5X3Y|Babsbny earned he...|                   0|                     0|    4|1305417600|Two enthusiastic ...|\"Okay, so I admit...|\n",
      "|250108|B0029NII3C|A2Z03H9LUXPEFV|          J Gilstrap|                   0|                     0|    3|1275004800|      Finniky Kitty!|I have to say tha...|\n",
      "|250116|B0013MEB40|A3NEAETOSXDBOM|   Stephen M. Charme|                   0|                     0|    5|1299801600|Our favorite groc...|This is not a gou...|\n",
      "|250124|B0013MEB40|A3D81H6GXY7RXD|            Einstein|                   3|                     6|    2|1241568000|stick with the Ke...|Chips Ahoy, chewy...|\n",
      "|250132|B005UBH8WC| AY12DBB0U420B|       Gary Peterson|                   0|                     0|    5|1336348800|A Favorite of My ...|I've been using I...|\n",
      "|250140|B001EQ57QG|A37EOLAE5SITDL|           K. Miller|                   0|                     0|    4|1343174400|         great value|\"I use these for ...|\n",
      "|250148|B001FB6AT8|A21X71JL6KP9XE|      Robert Ingalls|                   0|                     0|    5|1300320000|Great but Hard to...|Not the easiest p...|\n",
      "|250156|B003DNL9YM| A4EEI98J1IQIW|               y2kbj|                   1|                     1|    5|1310860800|Hard to find flav...|Excellent product...|\n",
      "|250164|B003DNL9YM|A2Z9JO4SKLEEUE|\"Michael Fletcher...|                   0|                     0|    5|1303171200|Best of any powde...|Hooked on this fl...|\n",
      "|250172|B002C56O10|A1Q5WGU22LHZNQ|        MV Ridgewood|                   1|                     1|    4|1321228800|Delicioua Pasta -...|\"I have trouble f...|\n",
      "|250180|B000FGXT3E| AHPF30RZZGF5L|LORRAINE J CAROPRESO|                   1|                     1|    5|1308873600|BEST TEA. BEST SE...|\"I HAVE ORDERED \"...|\n",
      "|250188|B0027UYT4O| A4O09N7ZP26RD|         James Sweet|                  16|                    17|    5|1267401600|     Monkey Platter!|This tray makes a...|\n",
      "|250196|B0027UYT4O|A3NHZERVB4YV0O|              bygwit|                   4|                     4|    4|1291334400|Great product, bu...|I have the Beaba ...|\n",
      "|250204|B0027UYT4O|A1FZGVS6LOOZ17|                  AR|                   1|                     1|    5|1314835200|One of my favorit...|The Beaba Multipo...|\n",
      "|250212|B0027UYT4O|A1S7U6E1L3GOV3|              Gary K|                   1|                     1|    5|1292889600|Great little free...|The Beaba freezer...|\n",
      "|250220|B0027UYT4O|A3IKVQW0GB8T6X|\"N. Travinsky \"\"b...|                   1|                     1|    4|1269907200|       yummy in pink|I've been making ...|\n",
      "|250228|B0027UYT4O|A32UXPP7DL8KAI|     Steve Aquillano|                   0|                     0|    4|1349654400|Works perfectly, ...|I bought these to...|\n",
      "+------+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the number of stars to an integer to do analysis on and then dropping the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat=dat.withColumn(\"Stars\", col(\"Score\").cast(IntegerType()))\n",
    "dat=dat.withColumn(\"Likes\", col(\"HelpfulnessNumerator\").cast(IntegerType()))\n",
    "dat=dat.withColumn(\"TotalHelp\", col(\"HelpfulnessDenominator\").cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat=dat.drop(\"Score\",\"HelpfulnessNumerator\",\"HelpfulnessDemoninator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|   Id|avg(Stars)|\n",
      "+-----+----------+\n",
      "| 2659|       5.0|\n",
      "| 5803|       5.0|\n",
      "| 9427|       5.0|\n",
      "|12027|       5.0|\n",
      "|15619|       5.0|\n",
      "|16339|       5.0|\n",
      "|18051|       5.0|\n",
      "|18979|       5.0|\n",
      "|20683|       5.0|\n",
      "|23571|       5.0|\n",
      "|24171|       1.0|\n",
      "|24347|       4.0|\n",
      "|26755|       4.0|\n",
      "|31035|       5.0|\n",
      "|32539|       5.0|\n",
      "|35947|       4.0|\n",
      "|36131|       5.0|\n",
      "|36355|       5.0|\n",
      "|37251|       5.0|\n",
      "|37307|       5.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dat.groupby(\"Id\").avg(\"Stars\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             Summary|\n",
      "+--------------------+\n",
      "|\"\"\"Delight\"\" says...|\n",
      "|The Best Hot Sauc...|\n",
      "|  GREAT SWEET CANDY!|\n",
      "|     Nasty No flavor|\n",
      "|Great Irish oatme...|\n",
      "|          Food-Great|\n",
      "|       Don't like it|\n",
      "|Awsome - Kids in ...|\n",
      "|Low Carb Alternat...|\n",
      "|     nothing special|\n",
      "|Forget Molecular ...|\n",
      "|Great food for my...|\n",
      "|Perfect for our E...|\n",
      "|       disappointing|\n",
      "|          Tea review|\n",
      "| Good for Feline UTI|\n",
      "|Amazing to the la...|\n",
      "|    Simply the BEST!|\n",
      "|BROKEN BOTTLE BOT...|\n",
      "|              JELL-O|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dat.select(\"Summary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code runs the TF-IDF hashing method to convert the words to a feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"Summary\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(dat)\n",
    "dat = wordsData\n",
    "tokenizer2 = Tokenizer(inputCol=\"Text\", outputCol=\"wordsText\")\n",
    "textData = tokenizer2.transform(dat)\n",
    "dat = textData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- ProductId: string (nullable = true)\n",
      " |-- UserId: string (nullable = true)\n",
      " |-- ProfileName: string (nullable = true)\n",
      " |-- HelpfulnessDenominator: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Summary: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      " |-- Stars: integer (nullable = true)\n",
      " |-- Likes: integer (nullable = true)\n",
      " |-- TotalHelp: integer (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- wordsText: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Id=3, ProductId='B000LQOCH0', UserId='ABXLMWJIXXAIN', ProfileName='\"Natalia Corres \"\"Natalia Corres\"\"\"', HelpfulnessDenominator='1', Time='1219017600', Summary='\"\"\"Delight\"\" says it all\"', Text='\"This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis\\' \"\"The Lion', Stars=4, Likes=1, TotalHelp=1, words=['\"\"\"delight\"\"', 'says', 'it', 'all\"'], wordsText=['\"this', 'is', 'a', 'confection', 'that', 'has', 'been', 'around', 'a', 'few', 'centuries.', '', 'it', 'is', 'a', 'light,', 'pillowy', 'citrus', 'gelatin', 'with', 'nuts', '-', 'in', 'this', 'case', 'filberts.', 'and', 'it', 'is', 'cut', 'into', 'tiny', 'squares', 'and', 'then', 'liberally', 'coated', 'with', 'powdered', 'sugar.', '', 'and', 'it', 'is', 'a', 'tiny', 'mouthful', 'of', 'heaven.', '', 'not', 'too', 'chewy,', 'and', 'very', 'flavorful.', '', 'i', 'highly', 'recommend', 'this', 'yummy', 'treat.', '', 'if', 'you', 'are', 'familiar', 'with', 'the', 'story', 'of', 'c.s.', \"lewis'\", '\"\"the', 'lion'])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.printSchema()\n",
    "dat.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawSum\")\n",
    "dat = hashingTF.transform(dat)\n",
    "\n",
    "hashingTF2 = HashingTF(inputCol=\"wordsText\", outputCol=\"rawWords\")\n",
    "featurizedData = hashingTF2.transform(dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              rawSum|\n",
      "+--------------------+\n",
      "|(262144,[37852,41...|\n",
      "|(262144,[29582,49...|\n",
      "|(262144,[2692,378...|\n",
      "|(262144,[8610,156...|\n",
      "|(262144,[17444,17...|\n",
      "|(262144,[7367,961...|\n",
      "|(262144,[103838,1...|\n",
      "|(262144,[9639,378...|\n",
      "|(262144,[138356,2...|\n",
      "|(262144,[2437,918...|\n",
      "|(262144,[2437,363...|\n",
      "|(262144,[9639,592...|\n",
      "|(262144,[16332,23...|\n",
      "|(262144,[13963,87...|\n",
      "|(262144,[122823,1...|\n",
      "|(262144,[96638,13...|\n",
      "|(262144,[9639,378...|\n",
      "|(262144,[16332,75...|\n",
      "|(262144,[78,85161...|\n",
      "|(262144,[12888,16...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurizedData.select(\"rawSum\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"rawSum\", outputCol=\"featuresSum\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         featuresSum|\n",
      "+--------------------+\n",
      "|(262144,[10804,86...|\n",
      "|(262144,[42343,10...|\n",
      "|(262144,[138356,1...|\n",
      "|(262144,[93123,15...|\n",
      "|(262144,[1911,163...|\n",
      "|(262144,[18469],[...|\n",
      "|(262144,[86175,11...|\n",
      "|(262144,[33933,45...|\n",
      "|(262144,[38270,61...|\n",
      "|(262144,[46252,15...|\n",
      "|(262144,[33209,45...|\n",
      "|(262144,[16332,37...|\n",
      "|(262144,[9616,163...|\n",
      "|(262144,[77142],[...|\n",
      "|(262144,[127412,2...|\n",
      "|(262144,[16332,35...|\n",
      "|(262144,[5381,164...|\n",
      "|(262144,[16457,10...|\n",
      "|(262144,[61666,12...|\n",
      "|(262144,[47237],[...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledData.select(\"featuresSum\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are performing our actual machine learning on the summary column as we feel there are more key words in the summary when compared to the discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        featuresText|\n",
      "+--------------------+\n",
      "|(262144,[10804,86...|\n",
      "|(262144,[42343,10...|\n",
      "|(262144,[138356,1...|\n",
      "|(262144,[93123,15...|\n",
      "|(262144,[1911,163...|\n",
      "|(262144,[18469],[...|\n",
      "|(262144,[86175,11...|\n",
      "|(262144,[33933,45...|\n",
      "|(262144,[38270,61...|\n",
      "|(262144,[46252,15...|\n",
      "|(262144,[33209,45...|\n",
      "|(262144,[16332,37...|\n",
      "|(262144,[9616,163...|\n",
      "|(262144,[77142],[...|\n",
      "|(262144,[127412,2...|\n",
      "|(262144,[16332,35...|\n",
      "|(262144,[5381,164...|\n",
      "|(262144,[16457,10...|\n",
      "|(262144,[61666,12...|\n",
      "|(262144,[47237],[...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol=\"rawSum\", outputCol=\"featuresText\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "rescaledData.select(\"featuresText\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|Stars|        featuresText|\n",
      "+-----+--------------------+\n",
      "|    3|(262144,[37852,41...|\n",
      "|    5|(262144,[29582,49...|\n",
      "|    5|(262144,[2692,378...|\n",
      "|    4|(262144,[8610,156...|\n",
      "|    3|(262144,[17444,17...|\n",
      "|    5|(262144,[7367,961...|\n",
      "|    2|(262144,[103838,1...|\n",
      "|    5|(262144,[9639,378...|\n",
      "|    4|(262144,[138356,2...|\n",
      "|    5|(262144,[2437,918...|\n",
      "|    5|(262144,[2437,363...|\n",
      "|    5|(262144,[9639,592...|\n",
      "|    4|(262144,[16332,23...|\n",
      "|    5|(262144,[13963,87...|\n",
      "|    5|(262144,[122823,1...|\n",
      "|    4|(262144,[96638,13...|\n",
      "|    5|(262144,[9639,378...|\n",
      "|    5|(262144,[16332,75...|\n",
      "|    4|(262144,[78,85161...|\n",
      "|    4|(262144,[12888,16...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+--------------------+\n",
      "|Stars|             Summary|\n",
      "+-----+--------------------+\n",
      "|    3|My cats love this...|\n",
      "|    5|\"Just what \"\"The ...|\n",
      "|    5|My Cat Loves Whis...|\n",
      "|    4|Two enthusiastic ...|\n",
      "|    3|      Finniky Kitty!|\n",
      "|    5|Our favorite groc...|\n",
      "|    2|stick with the Ke...|\n",
      "|    5|A Favorite of My ...|\n",
      "|    4|         great value|\n",
      "|    5|Great but Hard to...|\n",
      "|    5|Hard to find flav...|\n",
      "|    5|Best of any powde...|\n",
      "|    4|Delicioua Pasta -...|\n",
      "|    5|BEST TEA. BEST SE...|\n",
      "|    5|     Monkey Platter!|\n",
      "|    4|Great product, bu...|\n",
      "|    5|One of my favorit...|\n",
      "|    5|Great little free...|\n",
      "|    4|       yummy in pink|\n",
      "|    4|Works perfectly, ...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledData.select(\"Stars\", \"featuresText\").show()\n",
    "dat.select(\"Stars\", \"Summary\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- ProductId: string (nullable = true)\n",
      " |-- UserId: string (nullable = true)\n",
      " |-- ProfileName: string (nullable = true)\n",
      " |-- HelpfulnessDenominator: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Summary: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      " |-- Stars: integer (nullable = true)\n",
      " |-- Likes: integer (nullable = true)\n",
      " |-- TotalHelp: integer (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- wordsText: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- rawSum: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dat.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a 10/90 split just to get our data to run as it takes about 45 mins with this split and hours with a proper split. This is something which would be aided by the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- ProductId: string (nullable = true)\n",
      " |-- UserId: string (nullable = true)\n",
      " |-- ProfileName: string (nullable = true)\n",
      " |-- HelpfulnessDenominator: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Summary: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- Likes: integer (nullable = true)\n",
      " |-- TotalHelp: integer (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- wordsText: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- rawSum: vector (nullable = true)\n",
      " |-- rawWords: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledData =rescaledData.withColumnRenamed(\"Stars\", \"label\")\n",
    "rescaledData =rescaledData.withColumnRenamed(\"featuresText\", \"features\")\n",
    "rescaledData.printSchema()\n",
    "rescaledData = rescaledData.filter(rescaledData.features.isNotNull())\n",
    "rescaledData = rescaledData.filter(rescaledData.label.isNotNull())\n",
    "train, test = rescaledData.randomSplit([0.10, 0.90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train.select(\"label\")\n",
    "y = test.select(\"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assembler = VectorAssembler(\n",
    "#     inputCols='features',\n",
    "#     outputCol='features')\n",
    "\n",
    "# train_processed = assembler.transform(train)\n",
    "# test_processed = assembler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regression_model = LogisticRegression(maxIter=10, tol=1, fitIntercept=True)\n",
    "ovr = OneVsRest(classifier=regression_model)\n",
    "\n",
    "ovrModel = ovr.fit(train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only tested on 10% of the test data for the same reason: time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_processed, test_p = test.randomSplit([0.10, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = ovrModel.transform(test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.635963\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "\n",
    "# compute the classification error on test data.\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %g\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
